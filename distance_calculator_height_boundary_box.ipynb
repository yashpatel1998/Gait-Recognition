{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:48:26.750578Z",
     "start_time": "2019-02-26T13:48:26.006577Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import imutils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T12:51:39.256732Z",
     "start_time": "2019-02-25T12:51:39.250749Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset has greyscale images.240X320X8 i.e 8 is the depth of each pixel. each pixel can store 8bit info.\n",
    "#i.e each bit can for any number by combination of 8 bits of 0 and 1. \n",
    "#i.e any number between 0-255 can be taken by each pixel \n",
    "\n",
    "sample_image = cv2.imread(\"C:\\\\Users\\\\MUJ\\\\Desktop\\\\minor\\\\casia b\\\\silhouettes\\\\silhouette\\\\001\\\\nm-01\\\\090\\\\001-nm-01-090-047.png\",0)\n",
    "sample_image_rgb = cv2.imread(\"C:\\\\Users\\\\MUJ\\\\Desktop\\\\minor\\\\casia b\\\\silhouettes\\\\silhouette\\\\001\\\\nm-01\\\\090\\\\001-nm-01-090-047.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T06:17:56.852425Z",
     "start_time": "2019-02-26T06:15:18.584030Z"
    }
   },
   "outputs": [],
   "source": [
    "#cany first reduces noise in image by 5*5 filter then applies sobel kernel to find edge gradient and direction for each pixelAfter getting gradient magnitude and direction, a full scan of image is done to remove any unwanted pixels which may notconstitutethe edge.For this, at every pixel, pixel is checked if it is a local maximum in its neighborhood in the direction of gradientFor this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded. Those who lie between these two thresholds are classified edges or non-edges based on their connectivityIf they are connected to \"sure-edge\" pixels, they are considered to be part of edges. Otherwise, they are also discarded.\n",
    "#First argument is our input image. Second and third arguments are our minVal and maxVal respectively. Third argument is aperture_size. It is the size of Sobel kernel used for find image gradients. By default it is 3. Last argument is L2gradient which specifies the equation for finding gradient magnitude. If it is True, it uses the equation mentioned above which is more accurate, otherwise it uses this function: Edge_Gradient(G)=|Gx|+|Gy|. By default, it is False.\n",
    "egded_image = cv2.Canny(sample_image,200,255)#any pixel value lying greater than or equal to 200 is considered as edge value \n",
    "dilated = cv2.dilate(egded_image,None,iterations=1)\n",
    "cv2.imshow(\"edged\",egded_image)\n",
    "cv2.imshow(\"test\",sample_image)\n",
    "cv2.imshow(\"dialated\",dilated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T07:33:06.167775Z",
     "start_time": "2019-02-24T07:33:05.329434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 184)\n",
      "(313, 118)\n",
      "(277, 190)\n",
      "(293, 51)\n",
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "#Contour finding on original image\n",
    "\n",
    "#using otsu binarisation\n",
    "#For this, our cv.threshold() function is used, but pass an extra flag, cv.THRESH_OTSU. For threshold value, simply pass zero. \n",
    "#Then the algorithm finds the optimal threshold value and returns you as the second output, retVal. \n",
    "#If Otsu thresholding is not used, retVal is same as the threshold value you used.\n",
    "# cv2.threshold(greyscale image,0 as threshold value,cz the otsu will find its own threshold, will not use our given value,maxval,flag to use otsu)\n",
    "#thresh gets the modified image\n",
    "ret,thresh = cv2.threshold(sample_image,0,255,0)\n",
    "cv2.imshow(\"threshold_orig\",thresh)\n",
    "# three arguments in cv.findContours() function, first one is source image, second is contour retrieval mode, \n",
    "#third is contour approximation method. And it outputs a modified image, the contours and hierarchy. \n",
    "#contours is a Python list of all the contours in the image. \n",
    "#Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object.\n",
    "im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnt = contours[0]\n",
    "leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])\n",
    "rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])\n",
    "topmost = tuple(cnt[cnt[:,:,1].argmin()][0])\n",
    "bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])\n",
    "\n",
    "print(leftmost)\n",
    "print(rightmost)\n",
    "print(bottommost)\n",
    "print(topmost)\n",
    "\n",
    "\n",
    "# cv2.drawContours function is used. It can also be used to draw any shape provided you have its boundary points. \n",
    "#Its first argument is source image, second argument is the contours which should be passed as a Python list, \n",
    "#third argument is index of contours (useful when drawing individual contour. \n",
    "#To draw all contours, pass -1) and remaining arguments are color, thickness etc.\n",
    "cv2.drawContours(thresh, contours, -1, (0,255,0), 3)\n",
    "pixel = sample_image_rgb[leftmost[1],leftmost[0]]\n",
    "print(pixel)\n",
    "cv2.circle(thresh,(rightmost[1],bottommost[0]),50,(255,255,255),-1)\n",
    "\n",
    "cv2.imshow(\"test\",sample_image_rgb)\n",
    "cv2.imshow(\"threshold\",thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T12:53:20.386560Z",
     "start_time": "2019-02-25T12:53:13.289640Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277, 190)\n",
      "(313, 118)\n",
      "(313, 118)\n"
     ]
    }
   ],
   "source": [
    "# Main Code to find the left most and the rightmost points\n",
    "\n",
    "thresh = cv2.threshold(sample_image, 45, 255, cv2.THRESH_BINARY)[1]#further thresholding \n",
    "#erode function:-\n",
    "#So what happends is that, all the pixels near boundary will be discarded depending upon the size of kernel. \n",
    "#So the thickness or size of the foreground object decreases or simply white region decreases in the image. \n",
    "#It is useful for removing small white noises, detach two connected objects etc.\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "cv2.imshow(\"dilate\",thresh)\n",
    "cv2.imwrite(\"C:\\\\Users\\\\MUJ\\\\Desktop\\\\Gray_Image.jpg\", thresh.copy());\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Find the contour of the binary image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts) #graps only the contours points from cnts \n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "#area = cv2.contourArea(cnt[50])\n",
    "#print(\"area is \"+ str(area))\n",
    "\n",
    "#The extreme most points\n",
    "extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "print(extBot)\n",
    "print(extRight)\n",
    "cv2.drawContours(sample_image_rgb, [c], -1, (0, 255, 255), 2)\n",
    "cv2.circle(sample_image_rgb, (extRight[0],extBot[1]), 3, (0, 0, 255), -1)\n",
    "cv2.circle(sample_image_rgb, extBot, 3, (255, 255, 0), -1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"test\",sample_image_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(extRight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T05:59:34.893165Z",
     "start_time": "2019-02-26T05:59:34.873158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[291  52]]\n",
      "\n",
      " [[288  55]]\n",
      "\n",
      " [[288  69]]\n",
      "\n",
      " [[289  70]]\n",
      "\n",
      " [[289  72]]\n",
      "\n",
      " [[290  73]]\n",
      "\n",
      " [[291  73]]\n",
      "\n",
      " [[292  74]]\n",
      "\n",
      " [[292  82]]\n",
      "\n",
      " [[291  83]]\n",
      "\n",
      " [[291  86]]\n",
      "\n",
      " [[290  87]]\n",
      "\n",
      " [[290  98]]\n",
      "\n",
      " [[289  99]]\n",
      "\n",
      " [[289 100]]\n",
      "\n",
      " [[286 103]]\n",
      "\n",
      " [[286 106]]\n",
      "\n",
      " [[285 107]]\n",
      "\n",
      " [[285 108]]\n",
      "\n",
      " [[283 110]]\n",
      "\n",
      " [[283 111]]\n",
      "\n",
      " [[281 113]]\n",
      "\n",
      " [[281 117]]\n",
      "\n",
      " [[280 118]]\n",
      "\n",
      " [[278 118]]\n",
      "\n",
      " [[278 122]]\n",
      "\n",
      " [[282 122]]\n",
      "\n",
      " [[282 118]]\n",
      "\n",
      " [[283 117]]\n",
      "\n",
      " [[287 117]]\n",
      "\n",
      " [[288 118]]\n",
      "\n",
      " [[288 126]]\n",
      "\n",
      " [[289 127]]\n",
      "\n",
      " [[289 130]]\n",
      "\n",
      " [[288 131]]\n",
      "\n",
      " [[288 132]]\n",
      "\n",
      " [[287 133]]\n",
      "\n",
      " [[287 134]]\n",
      "\n",
      " [[286 135]]\n",
      "\n",
      " [[286 136]]\n",
      "\n",
      " [[284 138]]\n",
      "\n",
      " [[284 139]]\n",
      "\n",
      " [[283 140]]\n",
      "\n",
      " [[283 141]]\n",
      "\n",
      " [[281 143]]\n",
      "\n",
      " [[281 144]]\n",
      "\n",
      " [[280 145]]\n",
      "\n",
      " [[280 147]]\n",
      "\n",
      " [[279 148]]\n",
      "\n",
      " [[279 156]]\n",
      "\n",
      " [[280 157]]\n",
      "\n",
      " [[280 163]]\n",
      "\n",
      " [[281 164]]\n",
      "\n",
      " [[281 171]]\n",
      "\n",
      " [[282 172]]\n",
      "\n",
      " [[282 174]]\n",
      "\n",
      " [[283 175]]\n",
      "\n",
      " [[283 178]]\n",
      "\n",
      " [[282 179]]\n",
      "\n",
      " [[282 180]]\n",
      "\n",
      " [[280 182]]\n",
      "\n",
      " [[279 182]]\n",
      "\n",
      " [[277 184]]\n",
      "\n",
      " [[277 190]]\n",
      "\n",
      " [[282 190]]\n",
      "\n",
      " [[283 189]]\n",
      "\n",
      " [[285 189]]\n",
      "\n",
      " [[286 188]]\n",
      "\n",
      " [[296 188]]\n",
      "\n",
      " [[297 187]]\n",
      "\n",
      " [[303 187]]\n",
      "\n",
      " [[304 186]]\n",
      "\n",
      " [[305 186]]\n",
      "\n",
      " [[306 185]]\n",
      "\n",
      " [[306 179]]\n",
      "\n",
      " [[305 178]]\n",
      "\n",
      " [[305 174]]\n",
      "\n",
      " [[304 173]]\n",
      "\n",
      " [[304 162]]\n",
      "\n",
      " [[303 161]]\n",
      "\n",
      " [[303 150]]\n",
      "\n",
      " [[302 149]]\n",
      "\n",
      " [[302 136]]\n",
      "\n",
      " [[303 135]]\n",
      "\n",
      " [[303 134]]\n",
      "\n",
      " [[304 133]]\n",
      "\n",
      " [[309 133]]\n",
      "\n",
      " [[311 131]]\n",
      "\n",
      " [[311 127]]\n",
      "\n",
      " [[312 126]]\n",
      "\n",
      " [[312 119]]\n",
      "\n",
      " [[313 118]]\n",
      "\n",
      " [[313  87]]\n",
      "\n",
      " [[312  86]]\n",
      "\n",
      " [[312  82]]\n",
      "\n",
      " [[311  81]]\n",
      "\n",
      " [[311  80]]\n",
      "\n",
      " [[310  79]]\n",
      "\n",
      " [[310  78]]\n",
      "\n",
      " [[307  75]]\n",
      "\n",
      " [[306  75]]\n",
      "\n",
      " [[304  73]]\n",
      "\n",
      " [[303  73]]\n",
      "\n",
      " [[302  72]]\n",
      "\n",
      " [[302  71]]\n",
      "\n",
      " [[301  70]]\n",
      "\n",
      " [[301  66]]\n",
      "\n",
      " [[302  65]]\n",
      "\n",
      " [[302  63]]\n",
      "\n",
      " [[303  62]]\n",
      "\n",
      " [[303  57]]\n",
      "\n",
      " [[301  55]]\n",
      "\n",
      " [[301  54]]\n",
      "\n",
      " [[300  53]]\n",
      "\n",
      " [[299  53]]\n",
      "\n",
      " [[298  52]]]\n"
     ]
    }
   ],
   "source": [
    "print(cnts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T13:48:29.372619Z",
     "start_time": "2019-02-26T13:48:29.332568Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Main Code Over here\n",
    "\n",
    "\"\"\"\n",
    "def findDistance(sample_image,sample_image_rgb,para):\n",
    "    thresh = cv2.threshold(sample_image, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    #threshold gives a binary image as output,\n",
    "    #that contains foreground with white and background with black \n",
    "    #1. earlier it was grey scale image,now a binary image that contains either 0 or 1\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)#removes unnecessary noises near the boundry,detach almost connected parts aswell \n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)#thickens the boundry\n",
    "    #cv2.imshow(\"thresh\",thresh)\n",
    "    #cv2.imshow(\"sample\",sample_image)\n",
    "\n",
    "    #Find the ccontour of the binary image\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)#just graps the countours from above received cnts that also contains other info \n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    #The extreme most points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    \"\"\"\n",
    "        In the below code :\n",
    "            1) We are considering the points only below fist level that is coordinates with y value greater than that\n",
    "                of fist\n",
    "            2) In those values we are picking the rightmost and leftmost point that eventually comes out to\n",
    "                be the foot points\n",
    "        \n",
    "    \"\"\"\n",
    "    maximum_y_r = -999\n",
    "    maximum_x_r = -999\n",
    "    maximum_x_l = extLeft[0]\n",
    "    maximum_y_l = -999 \n",
    "    \n",
    "    for i in cnts[0]:\n",
    "        for k in i:\n",
    "            if k[1] > 150:\n",
    "                if maximum_x_r < k[0]:\n",
    "                    maximum_x_r = k[0]\n",
    "                    maximum_y_r = k[1]\n",
    "                        \n",
    "    maximum_x_l = maximum_x_r\n",
    "    maximum_y_l = -999 \n",
    "    for i in cnts[0]:\n",
    "        for k in i:\n",
    "            if k[1] > maximum_y_r - 10:\n",
    "                if maximum_x_l > k[0]:\n",
    "                    maximum_x_l = k[0]\n",
    "                    maximum_y_l = k[1]\n",
    "\n",
    "    cv2.circle(sample_image_rgb, (maximum_x_r,maximum_y_r), 3, (0, 0, 255), -1)#for creating points on image\n",
    "    cv2.circle(sample_image_rgb, (maximum_x_l,maximum_y_l), 3, (255, 255, 0), -1)\n",
    "    \n",
    "    #if y pixel of left foot is greater choose that y value \n",
    "    if maximum_y_l > maximum_y_r:\n",
    "        b=maximum_y_l\n",
    "    else:\n",
    "        b=maximum_y_r\n",
    "        \n",
    "    cv2.circle(sample_image_rgb,(extTop[0],b), 3, (255, 0, 255), -1)\n",
    "    cv2.circle(sample_image_rgb,extTop, 3, (255, 0, 0), -1)\n",
    "    #to make line of height \n",
    "    cv2.line(sample_image_rgb,(extTop[0],extTop[1]),(extTop[0],b),(255,0,0),1)\n",
    "    \n",
    "    x=extLeft[0]\n",
    "    y=extTop[1]\n",
    "    w=extRight[0]-extLeft[0]\n",
    "    h=extBot[1]-extTop[1]\n",
    "    \n",
    "    if para==1:\n",
    "        cv2.rectangle(sample_image_rgb,(x,y),(x+max(width_list),y+max(height_list)),(255,255,0),1)\n",
    "        cv2.imshow(\"box\",sample_image_rgb)\n",
    "    \n",
    "    cv2.imshow(\"sample\",sample_image_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    dx2 = (maximum_x_r-extBot[0])**2          # (200-10)^2\n",
    "    dy2 = (maximum_y_r-extBot[1])**2          # (300-20)^2\n",
    "    distance = math.sqrt(dx2 + dy2)\n",
    "    \n",
    "    \n",
    "\n",
    "    hgt = b-extTop[1]\n",
    "    \n",
    "    return distance,hgt,w,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def BoundingBox(sample_image_rgb,mean_height,w,x,y):\n",
    "#    cv2.rectangle(sample_image_rgb,(x,y),(x+w,(y+mean_height)),(255,255,0),1)\n",
    "    #cv2.imshow(\"box\",sample_image_rgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T14:09:19.651947Z",
     "start_time": "2019-02-26T14:08:55.799656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max width is78\n",
      "[56, 52, 41, 31, 19, 18, 18, 19, 18, 18, 75, 58, 50, 45, 39, 21, 34, 48, 60, 67, 73, 76, 73, 67, 59, 48, 37, 20, 21, 20, 20, 20, 18, 16, 63, 1589, 37, 34, 22, 17, 36, 50]\n",
      "height_list is:\n",
      "[123, 125, 126, 128, 130, 122, 121, 123, 124, 126, 127, 130, 127, 124, 121, 122, 124, 126, 127, 129, 131, 132, 131, 130, 128, 124, 122, 124, 125, 127, 128]\n",
      "mean height is:126\n",
      "Cycle Length = 1 \n"
     ]
    }
   ],
   "source": [
    "#images broken from between are not considered in calculating the height of the person and does not give apprpriate boundry box as well .\n",
    "sample_image_path = \"C:\\\\Users\\\\MUJ\\\\Desktop\\\\minor\\\\casia b\\\\silhouettes\\\\silhouette\\\\006\\\\nm-04\\\\090\\\\006-nm-04-090-\"\n",
    "sample_image_rgb_path = \"C:\\\\Users\\\\MUJ\\\\Desktop\\\\minor\\\\casia b\\\\silhouettes\\\\silhouette\\\\006\\\\nm-04\\\\090\\\\006-nm-04-090-\"\n",
    "\n",
    "distance_list = []\n",
    "height_list = []\n",
    "width_list=[]\n",
    "\n",
    "for i in range(69,111):\n",
    "    sample_image = cv2.imread(sample_image_path + \"{0:03}\".format(i) +\".png\",0)\n",
    "    sample_image_rgb = cv2.imread(sample_image_rgb_path + \"{0:03}\".format(i) +\".png\") \n",
    "    length,height,width,x,y = findDistance(sample_image,sample_image_rgb,0)\n",
    "    distance_list.append(round(length))\n",
    "    #discarding points that lie around the neck in height_list \n",
    "    if height>=120:\n",
    "        height_list.append(height)\n",
    "    width_list.append(width)   \n",
    "    \n",
    "mean_height=sum(height_list)//len(height_list)     \n",
    "\n",
    "#to make a boundry box pass 1 as a parameter in findDistance\n",
    "for i in range(69,111):\n",
    "    sample_image = cv2.imread(sample_image_path + \"{0:03}\".format(i) +\".png\",0)\n",
    "    sample_image_rgb = cv2.imread(sample_image_rgb_path + \"{0:03}\".format(i) +\".png\") \n",
    "    cv2.imshow(\"box\",sample_image_rgb)\n",
    "    length,height,width,x,y = findDistance(sample_image,sample_image_rgb,1)    \n",
    "    \n",
    "w=max(width_list)\n",
    "print(\"max width is\"+str(w))\n",
    "j=0\n",
    "\n",
    "\n",
    "#for i in range(69,111):\n",
    "#    sample_image_new = cv2.imread(sample_image_rgb_path + \"{0:03}\".format(i) +\".png\",0)    \n",
    "#    print(x_list[j],y_list[j])\n",
    " #   cv2.imshow(\"sample\",sample_image_new)\n",
    "  #  BoundingBox(sample_image_rgb,mean_height,w,x_list[j],y_list[j]) \n",
    "   # j=j+1\n",
    "\n",
    "print(distance_list)\n",
    "min_ = distance_list[0]\n",
    "count = 1\n",
    "cycle_length = []\n",
    "\n",
    "      \n",
    "#BoundingBox(sample_image_rgb,mean_height,width)\n",
    "\n",
    "for i in range(1,len(distance_list)):\n",
    "    temp = min_ - distance_list[i]\n",
    "    if temp > 0 and temp < 5:\n",
    "        count = i\n",
    "        break\n",
    "print(\"height_list is:\")        \n",
    "print(height_list) \n",
    "\n",
    "print(\"mean height is:\"+ str(mean_height))\n",
    "\n",
    "print(\"Cycle Length = {} \".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
